{
  "providers": {
    "openai": {
      "enabled": true,
      "models": [
        { "name": "gpt-4o-mini", "capabilities": ["summarize", "keywords", "sentiment", "vision", "emailReply", "translate"], "notes": "OpenAI multimodal small model with vision support." },
        { "name": "gpt-4.1-nano", "capabilities": ["summarize", "keywords", "sentiment", "askText", "emailReply", "translate"], "notes": "OpenAI lightweight model for fast, low-cost text tasks." },
        { "name": "gpt-5-nano", "capabilities": ["summarize", "keywords", "sentiment", "askText", "emailReply", "translate"], "notes": "OpenAI next-gen nano model with Q&A capabilities." }
      ]
    },
    "ollama": {
      "enabled": true,
      "models": [
        { "name": "llama3.2:latest", "capabilities": ["summarize", "keywords", "sentiment", "emailReply"], "notes": "Meta Llama 3.2 general-purpose model." },
        { "name": "qwen2.5-coder:latest", "capabilities": ["summarize", "keywords"], "notes": "Qwen 2.5 coder-optimized variant for code tasks." },
        { "name": "gemma2:2b", "capabilities": ["summarize", "keywords", "sentiment"], "notes": "Gemma 2 small variant for lightweight tasks." },
        { "name": "gemma3:4b", "capabilities": ["summarize", "keywords", "sentiment", "emailReply", "askText", "translate"], "notes": "Gemma 3 small variant for lightweight tasks with Q&A support." },
        { "name": "qwen2.5:0.5b", "capabilities": ["summarize", "keywords", "sentiment"], "notes": "Qwen 2.5 0.5B parameter model for ultra-light workloads." },
        { "name": "qwen2.5:1.5b", "capabilities": ["summarize", "keywords", "sentiment"], "notes": "Qwen 2.5 1.5B parameter model; balanced speed/quality." },
        { "name": "qwen2.5:3b", "capabilities": ["summarize", "keywords", "sentiment", "askText", "emailReply", "translate"], "notes": "Qwen 2.5 3B parameter model for stronger quality." },
        { "name": "qwen2.5:7b", "capabilities": ["summarize", "keywords", "sentiment"], "notes": "Qwen 2.5 7B parameter model for higher quality." },        
        { "name": "llama3.2:1b", "capabilities": ["summarize", "keywords", "sentiment", "askText", "emailReply", "translate"], "notes": "Llama 3.2 1B tiny variant for edge/light usage." },
        { "name": "llama3.2:3b", "capabilities": ["summarize", "keywords", "sentiment", "askText", "emailReply", "translate"], "notes": "Llama 3.2 3B small variant." },
        { "name": "gemma3:270m", "capabilities": ["summarize", "keywords", "sentiment", "askText", "emailReply"], "notes": "Gemma 3 270M instruct tuned; great for ultra-fast summarization on CPU." }
      ]
    },
    "openrouter": {
      "enabled": true,
      "models": [
        { "name": "anthropic/claude-3.5-sonnet", "capabilities": ["summarize", "keywords", "sentiment", "askText", "emailReply", "translate"], "notes": "Claude 3.5 Sonnet via OpenRouter; strong reasoning." },
        { "name": "openai/gpt-4o-mini", "capabilities": ["summarize", "keywords", "sentiment", "askText", "emailReply", "translate"], "notes": "OpenRouter proxy to GPT-4o mini." },
        { "name": "google/gemini-2.0-flash-lite-001", "capabilities": ["summarize", "keywords", "sentiment", "askText", "emailReply", "translate"], "notes": "Google Gemini 2.0 Flash Lite via OpenRouter with Q&A capabilities." },
        { "name": "google/gemini-2.5-flash-lite", "capabilities": ["summarize", "keywords", "sentiment", "askText", "emailReply", "translate"], "notes": "Google Gemini 2.5 Flash Lite via OpenRouter with 1M token context window for large document Q&A." },
        { "name": "openai/gpt-oss-20b", "capabilities": ["summarize", "keywords", "sentiment", "askText", "emailReply", "translate"], "notes": "OpenRouter proxy to GPT OSS 20B" },
        { "name": "openai/gpt-oss-120b", "capabilities": ["summarize", "keywords", "sentiment", "askText", "emailReply", "translate"], "notes": "OpenRouter proxy to GPT OSS 120B" }
      ]
    },
    "lmstudio": {
      "enabled": true,
      "models": [
        { "name": "gemma-3-270m-it", "capabilities": ["summarize", "keywords", "sentiment", "askText", "emailReply"], "notes": "Gemma 3 270M instruct tuned; great for ultra-fast summarization on CPU." },
        { "name": "llama-3.2-3b-instruct", "capabilities": ["summarize", "keywords", "sentiment", "askText", "emailReply", "translate"], "notes": "Llama 3.2 3B instruct; strong small model for summarization." }
      ]
    },
    "anthropic": {
      "enabled": true,
      "models": [
        { "name": "claude-3-haiku-20240307", "capabilities": ["summarize", "keywords", "sentiment", "askText", "emailReply", "translate"], "notes": "Anthropic Claude 3 Haiku; fast and cost-effective with Q&A support." }
      ]
    }
  }
}


